{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total variation supervised learning\n",
    "\n",
    "This code is an implementation of the Total variation model for supervised learning as described in eqns (11) and (12) in the paper:\n",
    "\n",
    "Supervised Learning via Euler's Elastica Models\n",
    "Tong Lin, Hanlin Xue, Ling Wang, Bo Huang, Hongbin Zha.\n",
    "Year: 2015, Volume: 16, Issue: 111, Pages: 3637âˆ’3686"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from pylab import *\n",
    "from autograd.util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes $\\phi_i(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(x,c,xi):\n",
    "    dim1,dim2 = xi.shape\n",
    "    return np.reshape(np.exp(-0.5*c*np.linalg.norm(x-xi, axis=1)**2),(dim1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes $u(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(x,c,xi,w):\n",
    "    dim1,dim2 = xi.shape\n",
    "    return np.sum(w*np.reshape(np.exp(-0.5*c*np.linalg.norm(x-xi, axis=1)**2),(dim1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes $\\psi(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi(x,c,xi,w):\n",
    "    m=len(w)\n",
    "    dim1,dim2 = x.shape\n",
    "    M=np.zeros((dim1,m))\n",
    "    for i in range(dim1):\n",
    "        M[i,:]=np.reshape(phi(x[i],c,xi),m)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes $g(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x,c,xi,w):\n",
    "    return np.sum(w*(x-xi)*phi(x,c,xi), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions compute the gradient $\\nabla u(x)$, the Laplacian $\\triangle u(x)$ and the Hessian $H(u(x))$ by using the definitions from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_u(x,c,xi,w):\n",
    "    return -c*g(x,c,xi,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_u(x,c,xi,w):\n",
    "    dim1,dim2 = xi.shape\n",
    "    return c*np.sum(w*np.reshape((c*(np.linalg.norm(x-xi, axis=1)**2)-dim2),(dim1,1))*phi(x,c,xi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_u(x,c,xi,w):\n",
    "    dim1,dim2 = xi.shape\n",
    "    p=-c*np.sum(w*np.reshape(np.exp(-0.5*c*np.linalg.norm(x-xi, axis=1)**2),(dim1,1)))*np.identity(dim2)\n",
    "    q=np.zeros((dim2,dim2))\n",
    "    pp=phi(x,c,xi)\n",
    "    for k in range(len(w)):\n",
    "        q=q+w[k]*(x-xi[k]).T.dot((x-xi[k]))*pp[k]\n",
    "    return p+(c**2)*q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following functions compute the gradient $\\nabla u(x)$, the Laplacian $\\triangle u(x)$ and the Hessian $H(u(x))$ by using automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd_gradient_u(x,c,xi,w):\n",
    "    nablau= np.grad(u,0)\n",
    "    return nablau(x,c,xi,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd_laplacian_u(x,c,xi,w):\n",
    "    h=np.autograd_hessian_u(x,c,xi,w)\n",
    "    return np.matrix.trace(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd_hessian_u(x,c,xi,w):\n",
    "    dim1,dim2 = xi.shape\n",
    "    def fun(x,c,xi,w):\n",
    "        return np.sum(w*np.reshape(np.exp(-0.5*c*np.linalg.norm(x-xi, axis=1)**2),(dim1,1)))\n",
    "    hess = np.hessian(fun)\n",
    "    return np.reshape(hess(x,c,xi,w),(dim2,dim2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes one entry of $\\partial u / \\partial t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dudtv(c,xi,w,y,lambdas):\n",
    "    m=len(w)\n",
    "    dudtvv=np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        dudtvv[i,0]=dudt(xi[i],c,xi,w,y[i],lambdas)\n",
    "    return dudtvv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computes the vector $\\partial u / \\partial t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dudt(x,c,xi,w,y,lambdas):\n",
    "    #here you may decide to use the automatic differentiation as above\n",
    "    uu=u(x,c,xi,w)\n",
    "    gu=gradient_u(x,c,xi,w)\n",
    "    hu=hessian_u(x,c,xi,w)\n",
    "    lu=laplacian_u(x,c,xi,w)\n",
    "    ngu=np.linalg.norm(gu)\n",
    "    return (lambdas*(lu-(gu.dot(hu).dot(gu.T))/(gu.dot(gu.T)))/ngu - uu + y).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following four functions are using for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training_core(c,xi,yin,lambdas,tol,tau):\n",
    "    dim1,dim2 = xi.shape\n",
    "    w=np.random.random((dim1,1))\n",
    "    PSI=psi(xi,c,xi,w)\n",
    "    w=np.linalg.inv(PSI.T.dot(PSI) + eta*np.identity(dim1)).dot(PSI.T.dot(yin))\n",
    "    w=np.reshape(w,(dim1,1))\n",
    "    \n",
    "    nr=1\n",
    "    i=0\n",
    "    while nr > tol:\n",
    "        if i==50:\n",
    "            break\n",
    "        i=i+1\n",
    "        PSI=psi(xi,c,xi,w)\n",
    "        DUDT=dudtv(c,xi,w,yin,lambdas)  \n",
    "        residual=np.linalg.inv(PSI.T.dot(PSI) + eta*np.identity(dim1)).dot(PSI.T.dot(DUDT))\n",
    "        w = w + tau*residual\n",
    "        nr=np.linalg.norm(residual)/len(w)\n",
    "        #print('iter= %3.0i, rel.residual= %1.2e' % (i,nr))\n",
    "    yout=psi(xi,c,xi,w).dot(w).T\n",
    "\n",
    "    inds=np.where(yout > 0)\n",
    "    yout[inds]=1\n",
    "    inds=np.where(yout < 0)\n",
    "    yout[inds]=-1\n",
    "    return yout, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(c,feature_training,lambdas,tol,tau,eta):\n",
    "    dim1,dim2 = feature_training.shape\n",
    "    x=np.zeros((1,dim2-1))\n",
    "\n",
    "    xi=np.zeros((dim1,dim2))\n",
    "    xi=feature_training[0:dim1,1:dim2]\n",
    "\n",
    "    yin=np.zeros((dim1,1))\n",
    "    yin[:,0]=feature_training[:,0]\n",
    "\n",
    "    yout, w =training_core(c,xi,yin,lambdas,tol,tau)\n",
    "    \n",
    "    Error=np.matrix.trace(yout!=yin)\n",
    "    Efficiency=100-100*Error/dim1\n",
    "   \n",
    "    return yout, w, Error, Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_step(feature_test,c,feature_training,w):\n",
    "    dim1,dim2 = feature_test.shape\n",
    "    xt=np.zeros((dim1,dim2))\n",
    "    xt=feature_test[0:dim1,1:dim2]\n",
    "\n",
    "    yin=np.zeros((dim1,1))\n",
    "    yin[:,0]=feature_test[:,0]\n",
    "\n",
    "    dim1,dim2 = feature_training.shape\n",
    "    xi=np.zeros((dim1,dim2))\n",
    "    xi=feature_training[0:dim1,1:dim2]\n",
    "\n",
    "    yout=psi(xt,c,xi,w).dot(w).T\n",
    "\n",
    "    inds=np.where(yout > 0)\n",
    "    yout[inds]=1\n",
    "    inds=np.where(yout < 0)\n",
    "    yout[inds]=-1\n",
    "\n",
    "    dim1,dim2 = feature_test.shape\n",
    "    Error=np.matrix.trace(yout!=yin)\n",
    "    Efficiency=100-100*Error/dim1\n",
    "   \n",
    "    return yout, Error, Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(MAX,c,lambdas,eta,tol,mydata,upperbound,lowerbound,set_size):\n",
    "    test_eff= np.zeros((MAX))\n",
    "    train_eff=np.zeros((MAX))\n",
    "    for I in range(MAX):\n",
    "        random_number = int(np.random.randint(upperbound+1,size=1))\n",
    "        feature_test = mydata[random_number:random_number+set_size,:]\n",
    "        feature_training = np.vstack(( mydata[0:random_number,:], mydata[random_number+set_size:m,:] ))\n",
    "\n",
    "        yout, w, train_error, train_eff[I] = training_step(c,feature_training,lambdas,tol,tau,eta)\n",
    "        yout, test_error, test_eff[I]= testing_step(feature_test,c,feature_training,w)  \n",
    "\n",
    "        inds=np.where(test_eff != 0)\n",
    "        indst=inds[0]\n",
    "        test_eff_mean=np.sum(test_eff[inds])/len(indst)\n",
    "        print('Training_Eff = %2.2f, Testing_eff= %2.2f, Mean_Test_Eff= %2.2f' % (train_eff[I], test_eff[I], test_eff_mean))\n",
    "        \n",
    "        file1 = open(\"resultsTVfile.txt\",\"a\") \n",
    "        s =  'c= ' + repr(c) + ', lambda= ' + repr(lambdas) + ', eta= ' + repr(eta) + ', trainef= ' + repr(train_eff[I]) + ', testef= ' + repr(test_eff[I])+ ', trainmeanef= ' + repr(test_eff_mean) + '\\n'\n",
    "        file1.write(s) \n",
    "        file1.close() \n",
    "    return test_eff_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the main part of the program.\n",
    "A dataset for liver disorder is used for testing. Data dimension is six and labels are binary.\n",
    "A search for the best parameters is done and results for each combination are saved into the file \"resultsTVfile.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing with lambda= 0.010, c= 0.100, eta= 0.001, tol= 0.005\n"
     ]
    }
   ],
   "source": [
    "mydata2 = np.loadtxt('bupaNormalized.dat')\n",
    "m,n = mydata2.shape\n",
    "mydata = np.hstack ((mydata2[:,6].reshape(m,1), mydata2[:,0:6]))\n",
    "\n",
    "N=5\n",
    "set_size=int(round(m/N))\n",
    "upperbound=m-set_size\n",
    "lowerbound=set_size\n",
    "\n",
    "MAX=10\n",
    "\n",
    "cc=np.array([0.1, 0.2, 0.5, 1.0, 2.0])\n",
    "lambdass=np.array([0.001, 0.01, 0.1, 1.0, 10.0, 100])\n",
    "etas=np.array([.001])\n",
    "\n",
    "# Parameter search vectors\n",
    "cc = np.arange(0.1, 2, np.log(2.))\n",
    "lambdass = np.arange(0.01, 1, np.log(2.))\n",
    "\n",
    "tol=0.005\n",
    "tau=0.1\n",
    "\n",
    "file1 = open(\"resultsTVfile.txt\",\"w\") \n",
    "file1.write(\"Results for TV model - May 23, 2020 \\n\") \n",
    "file1.close()\n",
    "\n",
    "for c in cc:\n",
    "    for lambdas in lambdass:\n",
    "        for eta in etas:\n",
    "            file1 = open(\"resultsTVfile.txt\",\"a\") \n",
    "            s =  'processing with c= ' + repr(c) + ', lambda= ' + repr(lambdas) + ', eta= ' + repr(eta) + '\\n'\n",
    "            file1.write(s)\n",
    "            file1.close()\n",
    "            print('Processing with lambda= %1.3f, c= %2.3f, eta= %1.3f, tol= %1.3f' % (lambdas,c,eta,tol))\n",
    "            test_classifier(MAX,c,lambdas,eta,tol,mydata,upperbound,lowerbound,set_size)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
